{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-07T23:00:03.475601Z",
     "iopub.status.busy": "2021-10-07T23:00:03.475342Z",
     "iopub.status.idle": "2021-10-07T23:00:03.48352Z",
     "shell.execute_reply": "2021-10-07T23:00:03.482286Z",
     "shell.execute_reply.started": "2021-10-07T23:00:03.475579Z"
    }
   },
   "source": [
    "<h2 style=\"font-weight: bold\">Digit Recognizer</h2>\n",
    "\n",
    "<h4>This is my third published notebook on Kaggle. Well! Well you guess it! it's gonna be about the Digit Recognizer Competition ðŸ˜„ðŸ˜„<br><br>I will be doing a simple EDA and Pre-Processing, the I will Build different models<br><br></h4>\n",
    "\n",
    "* <h5 style=\"font-weight: 700\">Your feedback is very welcome</h5>\n",
    "* <h5 style=\"font-weight: 700\">If you find this notebook useful, please don't forget to upvote it!</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.300677Z",
     "iopub.status.idle": "2021-10-09T22:47:43.301388Z",
     "shell.execute_reply": "2021-10-09T22:47:43.301234Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.301216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load a few helpful modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from   PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.302169Z",
     "iopub.status.idle": "2021-10-09T22:47:43.302991Z",
     "shell.execute_reply": "2021-10-09T22:47:43.302822Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.302803Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('../input/digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.303816Z",
     "iopub.status.idle": "2021-10-09T22:47:43.304544Z",
     "shell.execute_reply": "2021-10-09T22:47:43.304353Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.304327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Checking the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.305373Z",
     "iopub.status.idle": "2021-10-09T22:47:43.305959Z",
     "shell.execute_reply": "2021-10-09T22:47:43.305788Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.305767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check training data\n",
    "trainLabelCounts = train['label'].value_counts(sort = False)\n",
    "trainLabelCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.307201Z",
     "iopub.status.idle": "2021-10-09T22:47:43.30753Z",
     "shell.execute_reply": "2021-10-09T22:47:43.307359Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.307339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct the transform\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "# Get the device we're training on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_digits(df):\n",
    "    \"\"\"Loads images as PyTorch tensors\"\"\"\n",
    "    # Load the labels if they exist \n",
    "    # (they wont for the testing data)\n",
    "    labels = []\n",
    "    start_inx = 0\n",
    "    if 'label' in df.columns:\n",
    "        labels = [v for v in df.label.values]\n",
    "        start_inx = 1\n",
    "        \n",
    "    # Load the digit information\n",
    "    digits = []\n",
    "    for i in range(df.pixel0.size):\n",
    "        digit = df.iloc[i].astype(float).values[start_inx:]\n",
    "        digit = np.reshape(digit, (28,28))\n",
    "        digit = transform(digit).type('torch.FloatTensor')\n",
    "        if len(labels) > 0:\n",
    "            digits.append([digit, labels[i]])\n",
    "        else:\n",
    "            digits.append(digit)\n",
    "\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.308563Z",
     "iopub.status.idle": "2021-10-09T22:47:43.308863Z",
     "shell.execute_reply": "2021-10-09T22:47:43.308723Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.308702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = get_digits(train)\n",
    "\n",
    "# Some configuration parameters\n",
    "num_workers = 0    # number of subprocesses to use for data loading\n",
    "batch_size  = 64   # how many samples per batch to load\n",
    "valid_size  = 0.2  # percentage of training set to use as validation\n",
    "\n",
    "# Obtain training indices that will be used for validation\n",
    "num_train = len(train)\n",
    "indices   = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split     = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# Define samplers for obtaining training and validation batches\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# Construct the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "                    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, \n",
    "                    sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "# Test the size and shape of the output\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Modeling & Submitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.309826Z",
     "iopub.status.idle": "2021-10-09T22:47:43.310131Z",
     "shell.execute_reply": "2021-10-09T22:47:43.309992Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.309972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=576, out_features=512, bias=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_out(in_layers, stride, padding, kernel_size, pool_stride):\n",
    "    \"\"\"\n",
    "    Helper function for computing the number of outputs from a\n",
    "    conv layer\n",
    "    \"\"\"\n",
    "    return int((1+(in_layers - kernel_size + (2*padding))/stride)/pool_stride)\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Some helpful values\n",
    "        inputs      = [1,32,64,64]\n",
    "        kernel_size = [5,5,3]\n",
    "        stride      = [1,1,1]\n",
    "        pool_stride = [2,2,2]\n",
    "\n",
    "        # Layer lists\n",
    "        layers = []\n",
    "\n",
    "        self.out   = 28\n",
    "        self.depth = inputs[-1]\n",
    "        for i in range(len(kernel_size)):\n",
    "            # Get some variables\n",
    "            padding = int(kernel_size[i]/2)\n",
    "\n",
    "            # Define the output from this layer\n",
    "            self.out = calc_out(self.out, stride[i], padding,\n",
    "                                kernel_size[i], pool_stride[i])\n",
    "\n",
    "            # convolutional layer 1\n",
    "            layers.append(nn.Conv2d(inputs[i], inputs[i+1], kernel_size[i], \n",
    "                                       stride=stride[i], padding=padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            # convolutional layer 2\n",
    "            layers.append(nn.Conv2d(inputs[i+1], inputs[i+1], kernel_size[i], \n",
    "                                       stride=stride[i], padding=padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            # maxpool layer\n",
    "            layers.append(nn.MaxPool2d(pool_stride[i],pool_stride[i]))\n",
    "            layers.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        print(self.depth*self.out*self.out)\n",
    "        \n",
    "        # Now for our fully connected layers\n",
    "        layers2 = []\n",
    "        layers2.append(nn.Dropout(p=0.2))\n",
    "        layers2.append(nn.Linear(self.depth*self.out*self.out, 512))\n",
    "        layers2.append(nn.Dropout(p=0.2))\n",
    "        layers2.append(nn.Linear(512, 256))\n",
    "        layers2.append(nn.Dropout(p=0.2))\n",
    "        layers2.append(nn.Linear(256, 256))\n",
    "        layers2.append(nn.Dropout(p=0.2))\n",
    "        layers2.append(nn.Linear(256, 10))\n",
    "\n",
    "        self.fc_layers = nn.Sequential(*layers2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(-1, self.depth*self.out*self.out)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.311372Z",
     "iopub.status.idle": "2021-10-09T22:47:43.312105Z",
     "shell.execute_reply": "2021-10-09T22:47:43.311953Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.311935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.260248 \tValidation Loss: 0.015653\n",
      "Validation loss decreased (inf --> 0.015653).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 0.072273 \tValidation Loss: 0.010736\n",
      "Validation loss decreased (0.015653 --> 0.010736).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.055049 \tValidation Loss: 0.013053\n",
      "Epoch: 3 \tTraining Loss: 0.045629 \tValidation Loss: 0.007263\n",
      "Validation loss decreased (0.010736 --> 0.007263).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.041627 \tValidation Loss: 0.007377\n",
      "Epoch: 5 \tTraining Loss: 0.039624 \tValidation Loss: 0.006847\n",
      "Validation loss decreased (0.007263 --> 0.006847).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.040688 \tValidation Loss: 0.007305\n",
      "Epoch: 7 \tTraining Loss: 0.039148 \tValidation Loss: 0.006564\n",
      "Validation loss decreased (0.006847 --> 0.006564).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.032376 \tValidation Loss: 0.009442\n",
      "Epoch: 9 \tTraining Loss: 0.031862 \tValidation Loss: 0.010304\n",
      "Epoch: 10 \tTraining Loss: 0.032057 \tValidation Loss: 0.008883\n",
      "Epoch: 11 \tTraining Loss: 0.028822 \tValidation Loss: 0.007504\n",
      "Epoch: 12 \tTraining Loss: 0.036214 \tValidation Loss: 0.008042\n",
      "Epoch: 13 \tTraining Loss: 0.028385 \tValidation Loss: 0.009794\n",
      "Epoch: 14 \tTraining Loss: 0.028744 \tValidation Loss: 0.010057\n",
      "Epoch: 15 \tTraining Loss: 0.028451 \tValidation Loss: 0.008487\n",
      "Epoch: 16 \tTraining Loss: 0.028851 \tValidation Loss: 0.010360\n",
      "Epoch: 17 \tTraining Loss: 0.024519 \tValidation Loss: 0.009097\n",
      "Epoch: 18 \tTraining Loss: 0.027734 \tValidation Loss: 0.010471\n",
      "Epoch: 19 \tTraining Loss: 0.026355 \tValidation Loss: 0.009300\n",
      "Epoch: 20 \tTraining Loss: 0.027809 \tValidation Loss: 0.007424\n",
      "Epoch: 21 \tTraining Loss: 0.022997 \tValidation Loss: 0.009120\n",
      "Epoch: 22 \tTraining Loss: 0.025221 \tValidation Loss: 0.008741\n",
      "Epoch: 23 \tTraining Loss: 0.021145 \tValidation Loss: 0.009926\n",
      "Epoch: 24 \tTraining Loss: 0.021606 \tValidation Loss: 0.009413\n"
     ]
    }
   ],
   "source": [
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "# number of epochs to train the model\n",
    "n_epochs = 25 # you may increase this number to train a final model\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "model.to(device)\n",
    "tLoss, vLoss = [], []\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    #########\n",
    "    # train #\n",
    "    #########\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data   = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ############\n",
    "    # validate #\n",
    "    ############\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data   = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    tLoss.append(train_loss)\n",
    "    vLoss.append(valid_loss)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.312879Z",
     "iopub.status.idle": "2021-10-09T22:47:43.313559Z",
     "shell.execute_reply": "2021-10-09T22:47:43.313388Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.313368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the resulting loss over time\n",
    "plt.plot(tLoss, label='Training Loss')\n",
    "plt.plot(vLoss, label='Validation Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.31448Z",
     "iopub.status.idle": "2021-10-09T22:47:43.315284Z",
     "shell.execute_reply": "2021-10-09T22:47:43.315101Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.315076Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.316072Z",
     "iopub.status.idle": "2021-10-09T22:47:43.31708Z",
     "shell.execute_reply": "2021-10-09T22:47:43.31679Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.316757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.006564\n",
      "\n",
      "Test Accuracy of   0: 98% (793/802)\n",
      "Test Accuracy of   1: 99% (909/913)\n",
      "Test Accuracy of   2: 99% (875/879)\n",
      "Test Accuracy of   3: 99% (846/850)\n",
      "Test Accuracy of   4: 98% (786/795)\n",
      "Test Accuracy of   5: 98% (755/763)\n",
      "Test Accuracy of   6: 99% (831/836)\n",
      "Test Accuracy of   7: 99% (884/891)\n",
      "Test Accuracy of   8: 98% (779/788)\n",
      "Test Accuracy of   9: 98% (869/883)\n",
      "\n",
      "Test Accuracy (Overall): 99% (8327/8400)\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss     = 0.0\n",
    "class_correct = [0]*10\n",
    "class_total   = [0]*10\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# For generating confusion matrix\n",
    "conf_matrix = np.zeros((10,10))\n",
    "\n",
    "# iterate over test data\n",
    "for data, target in valid_loader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    data   = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if device == \"cpu\" else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(target.size(0)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        conf_matrix[label][pred.data[i]] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(valid_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %3s: %2d%% (%2d/%2d)' % (\n",
    "            i, 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %3s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.318206Z",
     "iopub.status.idle": "2021-10-09T22:47:43.319151Z",
     "shell.execute_reply": "2021-10-09T22:47:43.318901Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.318876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the test data loader\n",
    "test        = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "test_X      = get_digits(test)\n",
    "test_loader = torch.utils.data.DataLoader(test_X, batch_size=batch_size, \n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.320206Z",
     "iopub.status.idle": "2021-10-09T22:47:43.320947Z",
     "shell.execute_reply": "2021-10-09T22:47:43.320756Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.320735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create storage objects\n",
    "ImageId, Label = [],[]\n",
    "\n",
    "# Loop through the data and get the predictions\n",
    "for data in test_loader:\n",
    "    # Move tensors to GPU if CUDA is available\n",
    "    data = data.to(device)\n",
    "    # Make the predictions\n",
    "    output = model(data)\n",
    "    # Get the most likely predicted digit\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    for i in range(len(pred)):        \n",
    "        ImageId.append(len(ImageId)+1)\n",
    "        Label.append(pred[i].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-09T22:47:43.321845Z",
     "iopub.status.idle": "2021-10-09T22:47:43.322697Z",
     "shell.execute_reply": "2021-10-09T22:47:43.322537Z",
     "shell.execute_reply.started": "2021-10-09T22:47:43.322519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Submission\n",
    "output = pd.DataFrame(data={'ImageId':ImageId, 'Label':Label})\n",
    "output = output.to_csv(\"./output/Submission.csv\", index=False)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
