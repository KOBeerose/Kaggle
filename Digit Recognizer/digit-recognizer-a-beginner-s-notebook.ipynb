{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 style=\"font-weight: bold\">Digit Recognizer</h2>\n\n<h4>This is my third published notebook on Kaggle. Well! Well you guess it! it's gonna be about the Digit Recognizer Competition ðŸ˜„ðŸ˜„<br><br>I will be doing a simple EDA and Pre-Processing, the I will Build different models<br><br></h4>\n\n* <h5 style=\"font-weight: 700\">Your feedback is very welcome</h5>\n* <h5 style=\"font-weight: 700\">If you find this notebook useful, please don't forget to upvote it!</h5>\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-07T23:00:03.475342Z","iopub.execute_input":"2021-10-07T23:00:03.475601Z","iopub.status.idle":"2021-10-07T23:00:03.48352Z","shell.execute_reply.started":"2021-10-07T23:00:03.475579Z","shell.execute_reply":"2021-10-07T23:00:03.482286Z"}}},{"cell_type":"code","source":"# Load a few helpful modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport pandas as pd\nfrom   PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.300677Z","iopub.status.idle":"2021-10-09T22:47:43.301388Z","shell.execute_reply.started":"2021-10-09T22:47:43.301216Z","shell.execute_reply":"2021-10-09T22:47:43.301234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.302169Z","iopub.status.idle":"2021-10-09T22:47:43.302991Z","shell.execute_reply.started":"2021-10-09T22:47:43.302803Z","shell.execute_reply":"2021-10-09T22:47:43.302822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.303816Z","iopub.status.idle":"2021-10-09T22:47:43.304544Z","shell.execute_reply.started":"2021-10-09T22:47:43.304327Z","shell.execute_reply":"2021-10-09T22:47:43.304353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Checking the Data**","metadata":{}},{"cell_type":"code","source":"# check training data\ntrainLabelCounts = train['label'].value_counts(sort = False)\ntrainLabelCounts","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.305373Z","iopub.status.idle":"2021-10-09T22:47:43.305959Z","shell.execute_reply.started":"2021-10-09T22:47:43.305767Z","shell.execute_reply":"2021-10-09T22:47:43.305788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct the transform\ntransform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n\n# Get the device we're training on\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef get_digits(df):\n    \"\"\"Loads images as PyTorch tensors\"\"\"\n    # Load the labels if they exist \n    # (they wont for the testing data)\n    labels = []\n    start_inx = 0\n    if 'label' in df.columns:\n        labels = [v for v in df.label.values]\n        start_inx = 1\n        \n    # Load the digit information\n    digits = []\n    for i in range(df.pixel0.size):\n        digit = df.iloc[i].astype(float).values[start_inx:]\n        digit = np.reshape(digit, (28,28))\n        digit = transform(digit).type('torch.FloatTensor')\n        if len(labels) > 0:\n            digits.append([digit, labels[i]])\n        else:\n            digits.append(digit)\n\n    return digits","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.307201Z","iopub.status.idle":"2021-10-09T22:47:43.30753Z","shell.execute_reply.started":"2021-10-09T22:47:43.307339Z","shell.execute_reply":"2021-10-09T22:47:43.307359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training data\ntrain = get_digits(train)\n\n# Some configuration parameters\nnum_workers = 0    # number of subprocesses to use for data loading\nbatch_size  = 64   # how many samples per batch to load\nvalid_size  = 0.2  # percentage of training set to use as validation\n\n# Obtain training indices that will be used for validation\nnum_train = len(train)\nindices   = list(range(num_train))\nnp.random.shuffle(indices)\nsplit     = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# Define samplers for obtaining training and validation batches\nfrom torch.utils.data.sampler import SubsetRandomSampler\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# Construct the data loaders\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n                    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, \n                    sampler=valid_sampler, num_workers=num_workers)\n\n# Test the size and shape of the output\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(type(images))\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.308563Z","iopub.status.idle":"2021-10-09T22:47:43.308863Z","shell.execute_reply.started":"2021-10-09T22:47:43.308702Z","shell.execute_reply":"2021-10-09T22:47:43.308723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Modeling & Submitting**","metadata":{}},{"cell_type":"code","source":"def calc_out(in_layers, stride, padding, kernel_size, pool_stride):\n    \"\"\"\n    Helper function for computing the number of outputs from a\n    conv layer\n    \"\"\"\n    return int((1+(in_layers - kernel_size + (2*padding))/stride)/pool_stride)\n\n# define the CNN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        # Some helpful values\n        inputs      = [1,32,64,64]\n        kernel_size = [5,5,3]\n        stride      = [1,1,1]\n        pool_stride = [2,2,2]\n\n        # Layer lists\n        layers = []\n\n        self.out   = 28\n        self.depth = inputs[-1]\n        for i in range(len(kernel_size)):\n            # Get some variables\n            padding = int(kernel_size[i]/2)\n\n            # Define the output from this layer\n            self.out = calc_out(self.out, stride[i], padding,\n                                kernel_size[i], pool_stride[i])\n\n            # convolutional layer 1\n            layers.append(nn.Conv2d(inputs[i], inputs[i+1], kernel_size[i], \n                                       stride=stride[i], padding=padding))\n            layers.append(nn.ReLU())\n            \n            # convolutional layer 2\n            layers.append(nn.Conv2d(inputs[i+1], inputs[i+1], kernel_size[i], \n                                       stride=stride[i], padding=padding))\n            layers.append(nn.ReLU())\n            # maxpool layer\n            layers.append(nn.MaxPool2d(pool_stride[i],pool_stride[i]))\n            layers.append(nn.Dropout(p=0.2))\n\n        self.cnn_layers = nn.Sequential(*layers)\n        \n        print(self.depth*self.out*self.out)\n        \n        # Now for our fully connected layers\n        layers2 = []\n        layers2.append(nn.Dropout(p=0.2))\n        layers2.append(nn.Linear(self.depth*self.out*self.out, 512))\n        layers2.append(nn.Dropout(p=0.2))\n        layers2.append(nn.Linear(512, 256))\n        layers2.append(nn.Dropout(p=0.2))\n        layers2.append(nn.Linear(256, 256))\n        layers2.append(nn.Dropout(p=0.2))\n        layers2.append(nn.Linear(256, 10))\n\n        self.fc_layers = nn.Sequential(*layers2)\n\n    def forward(self, x):\n        x = self.cnn_layers(x)\n        x = x.view(-1, self.depth*self.out*self.out)\n        x = self.fc_layers(x)\n        return x\n    \n# create a complete CNN\nmodel = Net()\nmodel","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.309826Z","iopub.status.idle":"2021-10-09T22:47:43.310131Z","shell.execute_reply.started":"2021-10-09T22:47:43.309972Z","shell.execute_reply":"2021-10-09T22:47:43.309992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# specify loss function\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n# number of epochs to train the model\nn_epochs = 25 # you may increase this number to train a final model\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nmodel.to(device)\ntLoss, vLoss = [], []\nfor epoch in range(n_epochs):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    #########\n    # train #\n    #########\n    model.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        data   = data.to(device)\n        target = target.to(device)\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ############\n    # validate #\n    ############\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        data   = data.to(device)\n        target = target.to(device)\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss/len(train_loader.dataset)\n    valid_loss = valid_loss/len(valid_loader.dataset)\n    tLoss.append(train_loss)\n    vLoss.append(valid_loss)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_cifar.pt')\n        valid_loss_min = valid_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.311372Z","iopub.status.idle":"2021-10-09T22:47:43.312105Z","shell.execute_reply.started":"2021-10-09T22:47:43.311935Z","shell.execute_reply":"2021-10-09T22:47:43.311953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the resulting loss over time\nplt.plot(tLoss, label='Training Loss')\nplt.plot(vLoss, label='Validation Loss')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.312879Z","iopub.status.idle":"2021-10-09T22:47:43.313559Z","shell.execute_reply.started":"2021-10-09T22:47:43.313368Z","shell.execute_reply":"2021-10-09T22:47:43.313388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('model_cifar.pt'));","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.31448Z","iopub.status.idle":"2021-10-09T22:47:43.315284Z","shell.execute_reply.started":"2021-10-09T22:47:43.315076Z","shell.execute_reply":"2021-10-09T22:47:43.315101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# track test loss\ntest_loss     = 0.0\nclass_correct = [0]*10\nclass_total   = [0]*10\n\nmodel.eval()\n\n# For generating confusion matrix\nconf_matrix = np.zeros((10,10))\n\n# iterate over test data\nfor data, target in valid_loader:\n    # move tensors to GPU if CUDA is available\n    data   = data.to(device)\n    target = target.to(device)\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if device == \"cpu\" else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(target.size(0)):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n        \n        # Update confusion matrix\n        conf_matrix[label][pred.data[i]] += 1\n\n# average test loss\ntest_loss = test_loss/len(valid_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %3s: %2d%% (%2d/%2d)' % (\n            i, 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %3s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.316072Z","iopub.status.idle":"2021-10-09T22:47:43.31708Z","shell.execute_reply.started":"2021-10-09T22:47:43.316757Z","shell.execute_reply":"2021-10-09T22:47:43.31679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the test data loader\ntest        = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntest_X      = get_digits(test)\ntest_loader = torch.utils.data.DataLoader(test_X, batch_size=batch_size, \n                                          num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.318206Z","iopub.status.idle":"2021-10-09T22:47:43.319151Z","shell.execute_reply.started":"2021-10-09T22:47:43.318876Z","shell.execute_reply":"2021-10-09T22:47:43.318901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create storage objects\nImageId, Label = [],[]\n\n# Loop through the data and get the predictions\nfor data in test_loader:\n    # Move tensors to GPU if CUDA is available\n    data = data.to(device)\n    # Make the predictions\n    output = model(data)\n    # Get the most likely predicted digit\n    _, pred = torch.max(output, 1)\n    \n    for i in range(len(pred)):        \n        ImageId.append(len(ImageId)+1)\n        Label.append(pred[i].cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.320206Z","iopub.status.idle":"2021-10-09T22:47:43.320947Z","shell.execute_reply.started":"2021-10-09T22:47:43.320735Z","shell.execute_reply":"2021-10-09T22:47:43.320756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submission\noutput = pd.DataFrame(data={'ImageId':ImageId, 'Label':Label})\noutput = output.to_csv(\"submission.csv\", index=False)\nprint('done')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:47:43.321845Z","iopub.status.idle":"2021-10-09T22:47:43.322697Z","shell.execute_reply.started":"2021-10-09T22:47:43.322519Z","shell.execute_reply":"2021-10-09T22:47:43.322537Z"},"trusted":true},"execution_count":null,"outputs":[]}]}